{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_save(url, save_fp):\n",
    "    img_data = requests.get(url, timeout=5).content\n",
    "    with open(save_fp, 'wb') as handler:\n",
    "        handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "class MyArgs():\n",
    "    def __init__(self) -> None:\n",
    "        self.partitions = 4\n",
    "        self.part = 0\n",
    "        self.data_dir = 'data/WebVid'\n",
    "        self.csv_path ='data/WebVid/release/results_2M_train.csv'\n",
    "        self.processes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = MyArgs()\n",
    "# split dataset\n",
    "### preproc\n",
    "video_dir = os.path.join(args.data_dir, 'videos')\n",
    "if not os.path.exists(os.path.join(video_dir, 'videos')):\n",
    "    os.makedirs(os.path.join(video_dir, 'videos'))\n",
    "\n",
    "# ASSUMES THE CSV FILE HAS BEEN SPLIT INTO N PARTS\n",
    "partition_dir = args.csv_path.replace('.csv', f'_{args.partitions}')\n",
    "# if not, then split in this job.\n",
    "if not os.path.exists(partition_dir):\n",
    "    os.makedirs(partition_dir)\n",
    "    full_df = pd.read_csv(args.csv_path)\n",
    "    df_split = np.array_split(full_df, args.partitions)\n",
    "    for idx, subdf in enumerate(df_split):\n",
    "        subdf.to_csv(os.path.join(partition_dir, f'{idx}.csv'), index=False)\n",
    "\n",
    "relevant_fp = os.path.join(args.data_dir, 'relevant_videos_exists.txt')\n",
    "if os.path.isfile(relevant_fp):\n",
    "    exists = pd.read_csv(os.path.join(args.data_dir, 'relevant_videos_exists.txt'), names=['fn'])\n",
    "else:\n",
    "    exists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487525 367\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(os.path.join(partition_dir, f'{args.part}.csv'))\n",
    "df = pd.read_csv(args.csv_path)\n",
    "l = len(df)\n",
    "# df[df.isnull().values==True]\n",
    "df = df.dropna(axis=0,how='any')\n",
    "l_a = len(df)\n",
    "print(l_a, l - l_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoid</th>\n",
       "      <th>name</th>\n",
       "      <th>page_idx</th>\n",
       "      <th>page_dir</th>\n",
       "      <th>duration</th>\n",
       "      <th>contentUrl</th>\n",
       "      <th>rel_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31353427</td>\n",
       "      <td>Merida, mexico - may 23, 2017: tourists are wa...</td>\n",
       "      <td>19972</td>\n",
       "      <td>016401_016450</td>\n",
       "      <td>PT00H00M15S</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/31353...</td>\n",
       "      <td>016401_016450/31353427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31221946</td>\n",
       "      <td>Fun clown - 3d animation</td>\n",
       "      <td>23313</td>\n",
       "      <td>023301_023350</td>\n",
       "      <td>PT00H00M19S</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/31221...</td>\n",
       "      <td>023301_023350/31221946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14781349</td>\n",
       "      <td>Happy family using laptop on bed at home</td>\n",
       "      <td>15856</td>\n",
       "      <td>015851_015900</td>\n",
       "      <td>PT00H00M13S</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/14781...</td>\n",
       "      <td>015851_015900/14781349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25054445</td>\n",
       "      <td>11th march 2017. nakhon pathom, thailand. devo...</td>\n",
       "      <td>67495</td>\n",
       "      <td>067451_067500</td>\n",
       "      <td>PT00H00M06S</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/25054...</td>\n",
       "      <td>067451_067500/25054445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011030806</td>\n",
       "      <td>Decorate with pineapple sweet cake roll.</td>\n",
       "      <td>7058</td>\n",
       "      <td>069551_069600</td>\n",
       "      <td>PT00H00M06S</td>\n",
       "      <td>https://ak.picdn.net/shutterstock/videos/10110...</td>\n",
       "      <td>069551_069600/1011030806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      videoid                                               name  page_idx  \\\n",
       "0    31353427  Merida, mexico - may 23, 2017: tourists are wa...     19972   \n",
       "1    31221946                           Fun clown - 3d animation     23313   \n",
       "2    14781349           Happy family using laptop on bed at home     15856   \n",
       "3    25054445  11th march 2017. nakhon pathom, thailand. devo...     67495   \n",
       "4  1011030806           Decorate with pineapple sweet cake roll.      7058   \n",
       "\n",
       "        page_dir     duration  \\\n",
       "0  016401_016450  PT00H00M15S   \n",
       "1  023301_023350  PT00H00M19S   \n",
       "2  015851_015900  PT00H00M13S   \n",
       "3  067451_067500  PT00H00M06S   \n",
       "4  069551_069600  PT00H00M06S   \n",
       "\n",
       "                                          contentUrl                    rel_fn  \n",
       "0  https://ak.picdn.net/shutterstock/videos/31353...    016401_016450/31353427  \n",
       "1  https://ak.picdn.net/shutterstock/videos/31221...    023301_023350/31221946  \n",
       "2  https://ak.picdn.net/shutterstock/videos/14781...    015851_015900/14781349  \n",
       "3  https://ak.picdn.net/shutterstock/videos/25054...    067451_067500/25054445  \n",
       "4  https://ak.picdn.net/shutterstock/videos/10110...  069551_069600/1011030806  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rel_fn'] = df.apply(lambda x: os.path.join(x['page_dir'], str(x['videoid'])), axis=1)\n",
    "df['rel_fn'] = df['rel_fn'] + '.mp4'\n",
    "df = df[~df['rel_fn'].isin(exists)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3590"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists_to_dl = np.sort(df['page_dir'].unique())\n",
    "len(playlists_to_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 4666 jobs for page 000001_000050\n",
      "Spawning 4282 jobs for page 000051_000100\n",
      "Spawning 3476 jobs for page 000101_000150\n",
      "Spawning 2440 jobs for page 000151_000200\n",
      "Spawning 2556 jobs for page 000201_000250\n",
      "Spawning 2665 jobs for page 000251_000300\n",
      "Spawning 3536 jobs for page 000301_000350\n",
      "Spawning 3477 jobs for page 000351_000400\n",
      "Spawning 2688 jobs for page 000401_000450\n",
      "Spawning 2266 jobs for page 000451_000500\n",
      "Spawning 2699 jobs for page 000501_000550\n",
      "Spawning 3500 jobs for page 000551_000600\n",
      "Spawning 2442 jobs for page 000601_000650\n",
      "Spawning 3158 jobs for page 000651_000700\n",
      "Spawning 2433 jobs for page 000701_000750\n",
      "Spawning 2979 jobs for page 000751_000800\n",
      "Spawning 2791 jobs for page 000801_000850\n",
      "Spawning 2199 jobs for page 000851_000900\n",
      "Spawning 3103 jobs for page 000901_000950\n",
      "Spawning 2076 jobs for page 000951_001000\n",
      "Spawning 2792 jobs for page 001001_001050\n",
      "Spawning 3421 jobs for page 001051_001100\n",
      "Spawning 2456 jobs for page 001101_001150\n",
      "Spawning 3486 jobs for page 001151_001200\n",
      "Spawning 2940 jobs for page 001201_001250\n",
      "Spawning 2536 jobs for page 001251_001300\n",
      "Spawning 3642 jobs for page 001301_001350\n",
      "Spawning 2317 jobs for page 001351_001400\n",
      "Spawning 3446 jobs for page 001401_001450\n",
      "Spawning 2499 jobs for page 001451_001500\n",
      "Spawning 3000 jobs for page 001501_001550\n",
      "Spawning 3191 jobs for page 001551_001600\n",
      "Spawning 2153 jobs for page 001601_001650\n",
      "Spawning 2265 jobs for page 001651_001700\n",
      "Spawning 2891 jobs for page 001701_001750\n",
      "Spawning 2875 jobs for page 001751_001800\n",
      "Spawning 2805 jobs for page 001801_001850\n",
      "Spawning 2953 jobs for page 001851_001900\n",
      "Spawning 2838 jobs for page 001901_001950\n",
      "Spawning 2209 jobs for page 001951_002000\n",
      "Spawning 2133 jobs for page 002001_002050\n",
      "Spawning 3051 jobs for page 002051_002100\n",
      "Spawning 2141 jobs for page 002101_002150\n",
      "Spawning 2991 jobs for page 002151_002200\n",
      "Spawning 2433 jobs for page 002201_002250\n",
      "Spawning 2348 jobs for page 002251_002300\n",
      "Spawning 2343 jobs for page 002301_002350\n",
      "Spawning 3611 jobs for page 002351_002400\n",
      "Spawning 2823 jobs for page 002401_002450\n",
      "Spawning 2226 jobs for page 002451_002500\n",
      "Spawning 2413 jobs for page 002501_002550\n",
      "Spawning 2205 jobs for page 002551_002600\n",
      "Spawning 3597 jobs for page 002601_002650\n",
      "Spawning 2737 jobs for page 002651_002700\n",
      "Spawning 2404 jobs for page 002701_002750\n",
      "Spawning 2596 jobs for page 002751_002800\n",
      "Spawning 3262 jobs for page 002801_002850\n",
      "Spawning 3113 jobs for page 002851_002900\n",
      "Spawning 2394 jobs for page 002901_002950\n",
      "Spawning 2271 jobs for page 002951_003000\n",
      "Spawning 2781 jobs for page 003001_003050\n",
      "Spawning 2123 jobs for page 003051_003100\n",
      "Spawning 2386 jobs for page 003101_003150\n",
      "Spawning 3376 jobs for page 003151_003200\n",
      "Spawning 2217 jobs for page 003201_003250\n",
      "Spawning 3035 jobs for page 003251_003300\n",
      "Spawning 2872 jobs for page 003301_003350\n",
      "Spawning 2351 jobs for page 003351_003400\n",
      "Spawning 2139 jobs for page 003401_003450\n",
      "Spawning 3234 jobs for page 003451_003500\n",
      "Spawning 2083 jobs for page 003501_003550\n",
      "Spawning 2294 jobs for page 003551_003600\n",
      "Spawning 2111 jobs for page 003601_003650\n",
      "Spawning 2659 jobs for page 003651_003700\n",
      "Spawning 2606 jobs for page 003701_003750\n",
      "Spawning 2352 jobs for page 003751_003800\n",
      "Spawning 2458 jobs for page 003801_003850\n",
      "Spawning 3319 jobs for page 003851_003900\n",
      "Spawning 2535 jobs for page 003901_003950\n",
      "Spawning 2099 jobs for page 003951_004000\n",
      "Spawning 3181 jobs for page 004001_004050\n",
      "Spawning 3238 jobs for page 004051_004100\n",
      "Spawning 2875 jobs for page 004101_004150\n",
      "Spawning 3293 jobs for page 004151_004200\n",
      "Spawning 3318 jobs for page 004201_004250\n",
      "Spawning 2167 jobs for page 004251_004300\n",
      "Spawning 3433 jobs for page 004301_004350\n",
      "Spawning 3248 jobs for page 004351_004400\n",
      "Spawning 3211 jobs for page 004401_004450\n",
      "Spawning 2361 jobs for page 004451_004500\n",
      "Spawning 3113 jobs for page 004501_004550\n",
      "Spawning 3275 jobs for page 004551_004600\n",
      "Spawning 3346 jobs for page 004601_004650\n",
      "Spawning 2287 jobs for page 004651_004700\n",
      "Spawning 3391 jobs for page 004701_004750\n",
      "Spawning 2712 jobs for page 004751_004800\n",
      "Spawning 3087 jobs for page 004801_004850\n",
      "Spawning 2752 jobs for page 004851_004900\n",
      "Spawning 2368 jobs for page 004901_004950\n",
      "Spawning 2262 jobs for page 004951_005000\n",
      "Spawning 2718 jobs for page 005001_005050\n",
      "Spawning 2670 jobs for page 005051_005100\n",
      "Spawning 3639 jobs for page 005101_005150\n",
      "Spawning 3014 jobs for page 005151_005200\n",
      "Spawning 2291 jobs for page 005201_005250\n",
      "Spawning 2075 jobs for page 005251_005300\n",
      "Spawning 2412 jobs for page 005301_005350\n",
      "Spawning 3051 jobs for page 005351_005400\n",
      "Spawning 2201 jobs for page 005401_005450\n",
      "Spawning 2490 jobs for page 005451_005500\n",
      "Spawning 3308 jobs for page 005501_005550\n",
      "Spawning 2934 jobs for page 005551_005600\n",
      "Spawning 3033 jobs for page 005601_005650\n",
      "Spawning 2112 jobs for page 005651_005700\n",
      "Spawning 2180 jobs for page 005701_005750\n",
      "Spawning 2847 jobs for page 005751_005800\n",
      "Spawning 2534 jobs for page 005801_005850\n",
      "Spawning 2560 jobs for page 005851_005900\n",
      "Spawning 2710 jobs for page 005901_005950\n",
      "Spawning 2637 jobs for page 005951_006000\n",
      "Spawning 3379 jobs for page 006001_006050\n",
      "Spawning 3359 jobs for page 006051_006100\n",
      "Spawning 3335 jobs for page 006101_006150\n",
      "Spawning 3202 jobs for page 006151_006200\n",
      "Spawning 3231 jobs for page 006201_006250\n",
      "Spawning 2155 jobs for page 006251_006300\n",
      "Spawning 3435 jobs for page 006301_006350\n",
      "Spawning 3336 jobs for page 006351_006400\n",
      "Spawning 3146 jobs for page 006401_006450\n",
      "Spawning 2234 jobs for page 006451_006500\n",
      "Spawning 2843 jobs for page 006501_006550\n",
      "Spawning 3507 jobs for page 006551_006600\n"
     ]
    }
   ],
   "source": [
    "for page_dir in playlists_to_dl:\n",
    "    vid_dir_t = os.path.join(video_dir, page_dir)\n",
    "    pdf = df[df['page_dir'] == page_dir]\n",
    "    if len(pdf) > 0:\n",
    "        if not os.path.exists(vid_dir_t):\n",
    "            os.makedirs(vid_dir_t)\n",
    "\n",
    "        urls_todo = []\n",
    "        save_fps = []\n",
    "\n",
    "        for idx, row in pdf.iterrows():\n",
    "            video_fp = os.path.join(vid_dir_t, str(row['videoid']) + '.mp4')\n",
    "\n",
    "            urls_todo.append(row['contentUrl'])\n",
    "            save_fps.append(video_fp)\n",
    "\n",
    "        print(f'Spawning {len(urls_todo)} jobs for page {page_dir}')\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=args.processes) as executor:\n",
    "            future_to_url = {executor.submit(request_save, url, fp) for url, fp in zip(urls_todo, save_fps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a30bafa3dbc767c3b91272f6cd85377aa2073d1d1a663652dd0bcaf36cbd6e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('frozen': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
